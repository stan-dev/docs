<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Bayesian Statistics Using Stan</title>
  <meta name="description" content="Bayesian Statistics Using Stan, including Stan user’s guide with examples and programming techniques.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Bayesian Statistics Using Stan" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="img/logo-tm.pdf" />
  <meta property="og:description" content="Bayesian Statistics Using Stan, including Stan user’s guide with examples and programming techniques." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Bayesian Statistics Using Stan" />
  
  <meta name="twitter:description" content="Bayesian Statistics Using Stan, including Stan user’s guide with examples and programming techniques." />
  <meta name="twitter:image" content="img/logo-tm.pdf" />

<meta name="author" content="Stan Development Team">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="introduction.html">
<link rel="next" href="simple-examples.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="stan-manual.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li style="font-size:110%; font-weight:400; font-family: Verdana, Helvetica, sans; line-height:1.4; margin: 0.5em 0 0 1em">Bayesian Statistics with Stan</li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About this Book</a></li>
<li><a href="part-1-overview.html#part-1-overview"><i style="font-size: 110%; padding:1.5em 0 0 0; color:#990017;">Part 1: Overview</i></a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="prior-distributions-and-models-for-data.html"><a href="prior-distributions-and-models-for-data.html"><i class="fa fa-check"></i><b>2</b> Prior Distributions and Models for Data</a></li>
<li class="chapter" data-level="3" data-path="simple-examples.html"><a href="simple-examples.html"><i class="fa fa-check"></i><b>3</b> Simple Examples</a></li>
<li class="chapter" data-level="4" data-path="bayesian-workflow-1.html"><a href="bayesian-workflow-1.html"><i class="fa fa-check"></i><b>4</b> Bayesian Workflow</a></li>
<li><a href="example-models-part.html#example-models.part"><i style="font-size: 110%; color:#990017;">Part 2. Example Models</i></span></a></li>
<li class="chapter" data-level="5" data-path="regression-models.html"><a href="regression-models.html"><i class="fa fa-check"></i><b>5</b> Regression Models</a></li>
<li class="chapter" data-level="6" data-path="time-series-chapter.html"><a href="time-series-chapter.html"><i class="fa fa-check"></i><b>6</b> Time-Series Models</a></li>
<li class="chapter" data-level="7" data-path="missing-data-and-partially-known-parameters.html"><a href="missing-data-and-partially-known-parameters.html"><i class="fa fa-check"></i><b>7</b> Missing Data and Partially Known Parameters</a></li>
<li class="chapter" data-level="8" data-path="floating-point-arithmetic.html"><a href="floating-point-arithmetic.html"><i class="fa fa-check"></i><b>8</b> Floating Point Arithmetic</a></li>
<li class="chapter" data-level="9" data-path="truncated-or-censored-data.html"><a href="truncated-or-censored-data.html"><i class="fa fa-check"></i><b>9</b> Truncated or Censored Data</a></li>
<li class="chapter" data-level="10" data-path="mixture-modeling-chapter.html"><a href="mixture-modeling-chapter.html"><i class="fa fa-check"></i><b>10</b> Finite Mixtures</a></li>
<li class="chapter" data-level="11" data-path="measurement-error-and-meta-analysis.html"><a href="measurement-error-and-meta-analysis.html"><i class="fa fa-check"></i><b>11</b> Measurement Error and Meta-Analysis</a></li>
<li class="chapter" data-level="12" data-path="latent-discrete-chapter.html"><a href="latent-discrete-chapter.html"><i class="fa fa-check"></i><b>12</b> Latent Discrete Parameters</a></li>
<li class="chapter" data-level="13" data-path="sparse-ragged-chapter.html"><a href="sparse-ragged-chapter.html"><i class="fa fa-check"></i><b>13</b> Sparse and Ragged Data Structures</a></li>
<li class="chapter" data-level="14" data-path="clustering-chapter.html"><a href="clustering-chapter.html"><i class="fa fa-check"></i><b>14</b> Clustering Models</a></li>
<li class="chapter" data-level="15" data-path="gaussian-processes-chapter.html"><a href="gaussian-processes-chapter.html"><i class="fa fa-check"></i><b>15</b> Gaussian Processes</a></li>
<li class="chapter" data-level="16" data-path="directions-rotations-and-hyperspheres.html"><a href="directions-rotations-and-hyperspheres.html"><i class="fa fa-check"></i><b>16</b> Directions, Rotations, and Hyperspheres</a></li>
<li class="chapter" data-level="17" data-path="algebra-solver-chapter.html"><a href="algebra-solver-chapter.html"><i class="fa fa-check"></i><b>17</b> Solving Algebraic Equations</a></li>
<li class="chapter" data-level="18" data-path="ode-solver-chapter.html"><a href="ode-solver-chapter.html"><i class="fa fa-check"></i><b>18</b> Ordinary Differential Equations</a></li>
<li><a href="part-3-programming-techniques.html#part-3.-programming-techniques"><i style="font-size: 110%; color:#990017;">Part 3. Programming Techniques</i></a></li>
<li class="chapter" data-level="19" data-path="modeling-as-software-development.html"><a href="modeling-as-software-development.html"><i class="fa fa-check"></i><b>19</b> Modeling as Software Development</a></li>
<li class="chapter" data-level="20" data-path="matrices-vectors-and-arrays.html"><a href="matrices-vectors-and-arrays.html"><i class="fa fa-check"></i><b>20</b> Matrices, Vectors, and Arrays</a></li>
<li class="chapter" data-level="21" data-path="multi-indexing-chapter.html"><a href="multi-indexing-chapter.html"><i class="fa fa-check"></i><b>21</b> Multiple Indexing and Range Indexing</a></li>
<li class="chapter" data-level="22" data-path="functions-programming-chapter.html"><a href="functions-programming-chapter.html"><i class="fa fa-check"></i><b>22</b> User-Defined Functions</a></li>
<li class="chapter" data-level="23" data-path="custom-probability-functions-chapter.html"><a href="custom-probability-functions-chapter.html"><i class="fa fa-check"></i><b>23</b> Custom Probability Functions</a></li>
<li class="chapter" data-level="24" data-path="problematic-posteriors-chapter.html"><a href="problematic-posteriors-chapter.html"><i class="fa fa-check"></i><b>24</b> Problematic Posteriors</a></li>
<li class="chapter" data-level="25" data-path="change-of-variables-chapter.html"><a href="change-of-variables-chapter.html"><i class="fa fa-check"></i><b>25</b> Reparameterization and Change of Variables</a></li>
<li class="chapter" data-level="26" data-path="optimization-chapter.html"><a href="optimization-chapter.html"><i class="fa fa-check"></i><b>26</b> Efficiency Tuning</a></li>
<li class="chapter" data-level="27" data-path="map-reduce-chapter.html"><a href="map-reduce-chapter.html"><i class="fa fa-check"></i><b>27</b> Map-Reduce</a></li>
<li><a href="part-4-review-of-statistical-inference.html#part-4-review-of-statistical-inference"><i style="font-size: 110%; color:#990017;">Part 4: Review of Statistical Inference</i></a></li>
<li class="chapter" data-level="28" data-path="bayesian-data-analysis-1.html"><a href="bayesian-data-analysis-1.html"><i class="fa fa-check"></i><b>28</b> Bayesian Data Analysis</a></li>
<li class="chapter" data-level="29" data-path="mle-chapter.html"><a href="mle-chapter.html"><i class="fa fa-check"></i><b>29</b> Penalized Maximum Likelihood Point Estimation</a></li>
<li class="chapter" data-level="30" data-path="bayesian-point-estimation.html"><a href="bayesian-point-estimation.html"><i class="fa fa-check"></i><b>30</b> Bayesian Point Estimation</a></li>
<li class="chapter" data-level="31" data-path="vi-advanced-chapter.html"><a href="vi-advanced-chapter.html"><i class="fa fa-check"></i><b>31</b> Variational Inference</a></li>
<li><a href="appendices.html#appendices"><i style="font-size: 110%; color:#990017;">Appendices</i></a></li>
<li class="chapter" data-level="" data-path="appendix-1-stan-program-style-guide.html"><a href="appendix-1-stan-program-style-guide.html"><i class="fa fa-check"></i>Appendix 1. Stan Program Style Guide</a></li>
<li class="chapter" data-level="" data-path="stan-for-bugs-appendix.html"><a href="stan-for-bugs-appendix.html"><i class="fa fa-check"></i>Appendix 2. Transitioning from BUGS</a></li>
<li><a href="references.html#references"><i style="font-size: 110%; color:#990017;">References</i></a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bayesian Statistics Using Stan</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="prior-distributions-and-models-for-data" class="section level1">
<h1><span class="header-section-number">2</span> Prior Distributions and Models for Data</h1>
<div id="prior-likelihood-posterior-densities-bayes-as-information-aggregation" class="section level2">
<h2><span class="header-section-number">2.1</span> Prior, likelihood, posterior densities; Bayes as information aggregation</h2>
<p>As discussed in the context of the Hello World example in chapter 1, a
Stan model is constructed by adding to the objective function or
log-posterior density; each line in the model block with “target +=”
or a “~” symbol adds a term. The increments can come in any order, as
addition is commutative (<span class="math inline">\(X+Y = Y+X\)</span>). So your Stan model can start
with the log-prior and then add the log-likelihood, or the other way
around. Or the two can be interspersed. The structure of Stan can be
thought of as an implementation of the general idea of Bayesian
inference as information aggregation: Prior information, data
information, all of it is just information that is fed into the
inference engine.</p>
</div>
<div id="example-apparently-duplicate-priors" class="section level2">
<h2><span class="header-section-number">2.2</span> Example: apparently duplicate priors</h2>
<p>Start with the following simple Stan program:</p>
<pre><code>data {
  real y;
}
parameters {
  real theta;
}
model {
  theta ~ normal(0, 1);
  y ~ normal(theta, 1);
}</code></pre>
<p>Here, the prior and data happen to provide the same amount of
information about <span class="math inline">\(\theta\)</span>, and the posterior mean of <span class="math inline">\(\theta\)</span> will
fall halfway between the data, <span class="math inline">\(y\)</span>, and the prior mean, 0.</p>
<p>Now suppose we add a new line to the model block, apparently
duplicating the prior:</p>
<pre><code>model {
  theta ~ normal(0, 1);
  theta ~ normal(0, 1);
  y ~ normal(theta, 1);
}</code></pre>
<p>This looks weird. We have specified a model for <span class="math inline">\(\theta\)</span> twice. Does
this cause an error in the Stan program? Does Stan simply ignore the
duplicate code? Does the second “prior” overwrite the first?
Actually, no. The above model block is legal Stan code, as we can see
by replacing each line by its equivalent augmentation of the objective
function:</p>
<pre><code>model {
  target += normal(theta | 0, 1);
  target += normal(theta | 0, 1);
  target += normal(y | theta, 1);
}</code></pre>
<p>Each line adds a piece of information to the log posterior density.
In this simple example, all three lines of code contain the equivalent
amount of information—each is a normal density with scale 1—and so
the posterior mean of <span class="math inline">\(\theta\)</span> will be the average of the three
numbers, 0, 0, and <span class="math inline">\(y\)</span>.</p>
<p>Indeed, the above code is equivalent to this:</p>
<pre><code>model {
  theta ~ normal(0, 1/sqrt(2));
  y ~ normal(theta, 1);
}</code></pre>
<p>We cannot in general do this sort of simplification but it happens
that with the normal distribution these computations can be performed
analytically, as the product of two normal densities is itself normal.</p>
<p>As a practical matter, we do <em>not</em> recommend code like this:</p>
<pre><code>  theta ~ normal(0, 1);
  theta ~ normal(0, 1);</code></pre>
<p>as it just looks confusing. But understanding how it works gives
insight into the way that priors and data combine to express
information.</p>
</div>
<div id="concentration-of-the-likelihood" class="section level2">
<h2><span class="header-section-number">2.3</span> Concentration of the likelihood</h2>
<p>For any fixed model, as the sample size increases, the likelihood
becomes more informative. This can be seen, for example, in the
mdoels above, where each additional data point adds another term to
the likelihood in the implicit vector addition of the <code>target +=</code> or
<code>~</code> statement. See Chapter 4 of <em>Bayesian Data Analysis</em> for more on
this.</p>
</div>
<div id="problems-with-so-called-noninformative-priors" class="section level2">
<h2><span class="header-section-number">2.4</span> Problems with so-called noninformative priors</h2>
<p>Before discussing prior distributions more generally, we share a simple example.</p>
<p>You have a single parameter <span class="math inline">\(\theta\)</span> which we estimate using an
experiment which returns an estimate <span class="math inline">\(y\)</span>. For simplicity, assume the
estimate is unbiased, normally distributed, and with known standard
deviation that happens to equal 1. Thus, the data model is:
<span class="math display">\[
y \sim \mbox{normal}(\theta,1).
\]</span>
Now suppose you perform Bayesian inference using a uniform prior on
<span class="math inline">\(\theta\)</span>. Then your posterior distribution is simply (see, for
example, chapter 2 of <em>Bayesian Data Analysis</em>),
<span class="math display">\[
\theta|y \sim \mbox{normal}(y,1).
\]</span></p>
<p>OK, fine. Now suppose your estimate happens to be <span class="math inline">\(y=1\)</span>. There are
two ways of thinking about this:</p>
<ul>
<li><p>The observed data, 1 standard error away from 0, is completely
consistent with a true value of <span class="math inline">\(\theta=0\)</span>, or of low values of
<span class="math inline">\(\theta\)</span> that could be either positive or negative. From our usual
statistical perspective, we would say that the data are consistent
with pure noise, and we cannot learn much from these data alone.</p></li>
<li><p>From the Bayesian posterior distribution, we can compute that
<span class="math inline">\(\mbox{Pr}(\theta&gt;0) = 0.84\)</span> (in R, <code>pnorm(1)</code>), thus you should be
willing to bet with 5-to-1 odds that <span class="math inline">\(\theta\)</span> is positive.</p></li>
</ul>
<p>This seems wrong, the idea that something recognizable as pure noise
can lead to 5:1 posterior odds.</p>
<p>The problem is coming from the prior distribution. We can see this in
two ways. First, just directly, effects near zero are more common than
large effects.</p>
<p>Jakulin et al. (2008) argue that logistic regression coefficients are
usually less than 1. So let’s try combining normal(1,1) data with a
Cauchy(0,1) prior. It’s easy enough to do in Stan:</p>
<pre><code>data {
  real y;
}
parameters {
  real theta;
}
model {
  theta ~ cauchy (0, 1);
  y ~ normal(theta, 1);
}</code></pre>
<p>If we fit this model supplying data <span class="math inline">\(y=1\)</span>, and then from the resulting
simulations compute the posterior probability that <span class="math inline">\(\theta &gt; 0\)</span>, we
get 0.77, that is, roughly a 3:1 posterior probability that the effect
is positive.</p>
<p>Just to check that we’re not missing anything, let’s re-run using the
flat prior. New Stan model:</p>
<pre><code>data {
  real y;
}
parameters {
  real theta;
}
model {
  y ~ normal (theta, 1);
}</code></pre>
<p>and re-run with the same R code. This time, indeed, 84% of the posterior simulations of <span class="math inline">\(\theta\)</span> are greater than 0.</p>
<p>So far so good. Although one might argue that the posterior probability of 0.77 (from the inference given the unit Cauchy prior) is still too high. Perhaps we want a stronger prior? This sort of discussion is just fine. If you look at your posterior inference and it doesn’t make sense to you, this “doesn’t make sense” corresponds to additional prior information you haven’t included in your analysis.</p>
<p>OK, so that’s one way to consider the unreasonableness of a noninformative prior in this setting. It’s not so reasonable to believe that effects are equally likely to be any size. They’re generally more likely to be near zero.</p>
<p>The other way to see what’s going on with this example is to take that flat prior seriously. Suppose theta really could be just about anything—or, to keep things finite, suppose you wanted to assign theta a uniform prior distribution on <span class="math inline">\([-1000,1000]\)</span>, and then you gather enough data to estimate <span class="math inline">\(\theta\)</span> with a standard deviation of 1. Then, a priori, you’re nearly certain to gather very very strong information about the sign of <span class="math inline">\(\theta\)</span>. To start with, there’s a 0.998 chance that your estimate will be more than 2 standard errors away from zero so that your posterior odds about the sign of <span class="math inline">\(\theta\)</span> will be at least 20-to-1. And there’s a 0.995 chance that your estimate will be more than 5 standard errors away from zero.</p>
<p>So, in your prior distribution, this particular event—that <span class="math inline">\(y\)</span> is so close to zero that there is uncertainty about <span class="math inline">\(\theta\)</span>’s sign—is extremely unlikely. And it would be irrelevant that <span class="math inline">\(y\)</span> is not statistically significantly different from 0.</p>
<p>Modeling can be difficult. In some settings the data are strong and prior information is weak, and it’s not really worth the effort to think seriously about what external knowledge we have about the system being studied. Often, though, we do know a lot, and we’re interested in various questions where data are sparse, and we could be putting more effort into quantifying our prior distribution.</p>
<p>Upsetting situations—for example, the estimate of <span class="math inline">\(1 \pm 1\)</span> which leads to a seemingly too-strong claim of 5-to-1 odds in favor of a positive effect—are helpful in that they can reveal that we have prior information that we have not yet included in our models.</p>
</div>
<div id="general-priors.section" class="section level2">
<h2><span class="header-section-number">2.5</span> Priors</h2>
<p>The prior only matters where the likelihood is nonzero (and vice-versa). One way to think of the prior distribution is as a “regularization” or “soft constraint” on the parameters of the model. We discuss prior choice more fully on the <a href="https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations">prior choice wiki page</a>.</p>
<p>We consider 5 levels of priors:</p>
<ul>
<li><p>Flat prior;</p></li>
<li><p>Super-vague but proper prior: normal(0, 1e6);</p></li>
<li><p>Weakly informative prior, very weak: normal(0, 10);</p></li>
<li><p>Generic weakly informative prior: normal(0, 1);</p></li>
<li><p>Specific informative prior: normal(0.4, 0.2) or whatever. Sometimes this can be expressed as a scaling followed by a generic prior: theta = 0.4 + 0.2*z; z ~ normal(0, 1);</p></li>
</ul>
<p>In Stan, if you don’t supply any prior at all, you are implicitly using a flat prior. In general we don’t recommend this, but for many cases in this book, such as the Hello World example above, we use flat priors for simplicity and because we are focuseing on the expression of the data model or likelihood.</p>
<p>Setting up priors goes along with setting up the model. You want to set up your parameters so they are understandable, and then you will typically have some sense of their possible range, and you can use this to set up priors. If you have a lot of data, the prior won’t matter much, but there are lots of real examples where data are weak and it it is helpful to use an informative prior.</p>
<div id="background-reading" class="section level3 unnumbered">
<h3>Background Reading</h3>
<p>See <span class="citation">Gelman (<a href="#ref-Gelman:2006">2006</a>)</span> for an overview of choices for priors for
scale parameters, <span class="citation">Chung et al. (<a href="#ref-ChungEtAl:2013">2013</a>)</span> for an overview of choices
for scale priors in penalized maximum likelihood estimates, and
<span class="citation">Gelman et al. (<a href="#ref-GelmanJakulinPittauEtAl:2008">2008</a>)</span> for a discussion of prior choice
for regression coefficients.</p>
</div>
<div id="improper-uniform-priors" class="section level3 unnumbered">
<h3>Improper Uniform Priors</h3>
<p>The default in Stan is to provide uniform (or “flat”) priors on
parameters over their legal values as determined by their declared
constraints. A parameter declared without constraints is thus given a
uniform prior on <span class="math inline">\((-\infty,\infty)\)</span> by default, whereas a scale
parameter declared with a lower bound of zero gets an improper uniform
prior on <span class="math inline">\((0,\infty)\)</span>. Both of these priors are improper in the sense
that there is no way formulate a density function for them that
integrates to 1 over its support.</p>
<p>Stan allows models to be formulated with improper priors, but in order
for sampling or optimization to work, the data provided must ensure a
proper posterior. This usually requires a minimum quantity of data,
but can be useful as a starting point for inference and as a baseline
for sensitivity analysis (i.e., considering the effect the prior
has on the posterior).</p>
<p>Uniform priors are specific to the scale on which they are formulated.
For instance, we could give a scale parameter <span class="math inline">\(\sigma &gt; 0\)</span> a uniform
prior on <span class="math inline">\((0,\infty)\)</span>, <span class="math inline">\(q(\sigma) = c\)</span> (we use <span class="math inline">\(q\)</span> because the
“density” is not only unnormalized, but unnormalizable), or we could
work on the log scale and provide <span class="math inline">\(\log \sigma\)</span> a uniform prior on
<span class="math inline">\((-\infty,\infty)\)</span>, <span class="math inline">\(q(\log \sigma) = c\)</span>. These work out to be
different priors on <span class="math inline">\(\sigma\)</span> due to the Jacobian adjustment necessary
for the log transform.</p>
<p>Stan automatically applies the necessary Jacobian adjustment for
variables declared with constraints to ensure a uniform density on the
legal constrained values. This Jacobian adjustment is turned off when
optimization is being applied in order to produce appropriate maximum
likelihood estimates.</p>
</div>
<div id="proper-uniform-priors-interval-constraints" class="section level3 unnumbered">
<h3>Proper Uniform Priors: Interval Constraints</h3>
<p>It is possible to declare a variable with a proper uniform prior by
imposing both an upper and lower bound on it, for example,</p>
<pre><code>real&lt;lower=0.1, upper=2.7&gt; sigma;</code></pre>
<p>This will implicitly give <code>sigma</code> a <span class="math inline">\(\mathsf{Uniform}(0.1, 2.7)\)</span>
prior.</p>
<div id="matching-support-to-constraints" class="section level4 unnumbered">
<h4>Matching Support to Constraints</h4>
<p>As with all constraints, it is important that the model
provide support for all legal values of <code>sigma</code>. For example,
the following code constraints <code>sigma</code> to be positive, but then
imposes a bounded uniform prior on it.</p>
<pre><code>parameters {
  real&lt;lower=0&gt; sigma;
  ...
model {
  // *** bad *** : support narrower than constraint
  sigma ~ uniform(0.1, 2.7);</code></pre>
<p>The sampling statement imposes a limited support for <code>sigma</code> in
(0.1, 2.7), which is narrower than the support declared in the
constraint, namely <span class="math inline">\((0, \infty)\)</span>. This can cause the Stan program to
be difficult to initialize, hang during sampling, or devolve to a
random walk.</p>
</div>
<div id="boundary-estimates" class="section level4 unnumbered">
<h4>Boundary Estimates</h4>
<p>Estimates near boundaries for interval-constrained parameters
typically signal that the prior is not appropriate for the model. It
can also cause numerical problems with underflow and overflow when
sampling or optimizing.</p>
</div>
</div>
<div id="uninformative-proper-priors" class="section level3 unnumbered">
<h3>“Uninformative” Proper Priors</h3>
<p>It is uncommon to see models with priors on regression coefficients
such as <span class="math inline">\(\mathsf{normal}(0,1000)\)</span>.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<p>If the prior scale, such as 1000, is several orders of magnitude
larger than the estimated coefficients, then such a prior is
effectively providing no effect whatsoever.</p>
<p>We actively discourage users from using the default scale priors
suggested through the BUGS examples <span class="citation">(Lunn et al. <a href="#ref-LunnEtAl:2012">2012</a>)</span>, such as
<span class="math display">\[
\sigma^2 \sim \mathsf{InvGamma}(0.001, 0.001).
\]</span></p>
<p>Such priors concentrate too much probability mass outside of
reasonable posterior values, and unlike the symmetric wide normal
priors, can have the profound effect of skewing posteriors; see
<span class="citation">Gelman (<a href="#ref-Gelman:2006">2006</a>)</span> for examples and discussion.</p>
</div>
<div id="truncated-priors" class="section level3 unnumbered">
<h3>Truncated Priors</h3>
<p>If a variable is declared with a lower bound of zero, then assigning
it a normal prior in a Stan model produces the same effect as
providing a properly truncated half-normal prior. The truncation at
zero need not be specified as Stan only requires the density up to a
proportion. So a variable declared with</p>
<pre><code>real&lt;lower=0&gt; sigma;</code></pre>
<p>and given a prior</p>
<pre><code>sigma ~ normal(0, 1000);</code></pre>
<p>gives <code>sigma</code> a half-normal prior, technically</p>
<p><span class="math display">\[
p(\sigma)
\ = \
\frac{\mathsf{normal}(\sigma | 0, 1000)}
     {1 - \mathsf{NormalCDF}(0 | 0, 1000)}
\ \propto \
\mathsf{normal}(\sigma | 0, 1000),
\]</span></p>
<p>but Stan is able to avoid the calculation of the normal cumulative
distribution (CDF) function required to normalize the half-normal density.
If either the prior location or scale is a parameter or if the
truncation point is a parameter, the truncation cannot be dropped,
because the normal CDF term will not be a constant.</p>
</div>
<div id="weakly-informative-priors" class="section level3 unnumbered">
<h3>Weakly Informative Priors</h3>
<p>Typically a researcher will have some knowledge of the scale of the
variables being estimated. For instance, if we’re estimating an
intercept-only model for the mean population height for adult women,
then we know the answer is going to be somewhere in the one to three
meter range. That gives us information around which to form a weakly
informative prior.</p>
<p>Similarly, a logistic regression with predictors on the standard scale
(roughly zero mean, unit variance) is unlikely to have a
coefficient that’s larger than five in absolute value. In these
cases, it makes sense to provide a weakly informative prior such as
<span class="math inline">\(\mathsf{normal}(0,5)\)</span> for such a coefficient.</p>
<p>Weakly informative priors help control inference computationally and
statistically. Computationally, a prior increases the curvature
around the volume where the solution is expected to lie, which in turn
guides both gradient-based like L-BFGS and Hamiltonian Monte Carlo
sampling by not allowing them to stray too far from the location of a
surface. Statistically, a weakly informative prior is more sensible
for a problem like women’s mean height, because a diffuse prior
like <span class="math inline">\(\mathsf{normal}(0,1000)\)</span> will ensure that the vast majority of
the prior probability mass is outside the range of the expected
answer, which can overwhelm the inferences available from a small data
set.</p>
</div>
<div id="bounded-priors" class="section level3 unnumbered">
<h3>Bounded Priors</h3>
<p>Consider the women’s height example again. One way to formulate a
proper prior is to impose a uniform prior on a bounded scale. For
example, we could declare the parameter for mean women’s height to
have a lower bound of one meter and an upper bound of three meters.
Surely the answer has to lie in that range.</p>
<p>Similarly, it is uncommon to see priors for scale parameters that
impose lower bounds of zero and upper bounds of large numbers, such as
10,000.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<p>This provides roughly the same problem for estimation as a
diffuse inverse gamma prior on variance. We prefer to leave
parameters which are not absolutely physically constrained to float
and provide them informative priors. In the case of women’s height,
such a prior might be <span class="math inline">\(\mathsf{normal}(2,0.5)\)</span> on the scale of meters;
it concentrates 95% of its mass in the interval <span class="math inline">\((1,3)\)</span>, but still
allows values outside of that region.</p>
<p>In cases where bounded priors are used, the posterior fits should be
checked to make sure the parameter is not estimated at or close
to a boundary. This will not only cause computational problems, it
indicates a problem with the way the model is formulated. In such
cases, the interval should be widened to see where the parameter fits
without such constraints, or boundary-avoid priors should be used (see
the <a href="regression-models.html#hierarchical-priors.section">hierarchical priors section</a>.)</p>
</div>
<div id="fat-tailed-priors-and-default-priors" class="section level3 unnumbered">
<h3>Fat-Tailed Priors and Default Priors</h3>
<p>A reasonable alternative if we want to accommodate outliers is to use a
prior that concentrates most of mass around the area where values are
expected to be, but still leaves a lot of mass in its tails. One choice in such a situation is to use a Cauchy distribution for a
prior, which can concentrate its mass around its median, but has tails
that are so fat that the variance is infinite.</p>
<p>Without specific information, the Cauchy prior can be a reasonable default
parameter choice for regression coefficients
<span class="citation">Gelman et al. (<a href="#ref-GelmanJakulinPittauEtAl:2008">2008</a>)</span> and the half-Cauchy (coded
implicitly in Stan) a reasonable default choice for scale parameters
<span class="citation">Gelman (<a href="#ref-Gelman:2006">2006</a>)</span>.</p>
</div>
<div id="informative-priors" class="section level3 unnumbered">
<h3>Informative Priors</h3>
<p>Ideally, there will be substantive information about a problem that
can be included in an even tighter prior than a weakly informative
prior. This may come from actual prior experiments and thus be the
posterior of other data, it may come from meta-analysis, or it may
come simply by soliciting it from domain experts. All the goodness of
weakly informative priors applies, only with more strength.</p>
</div>
<div id="conjugacy" class="section level3 unnumbered">
<h3>Conjugacy</h3>
<p>Unlike in Gibbs sampling, there is no computational advantage to
providing conjugate priors (i.e., priors that produce posteriors in
the same family) in a Stan program.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> It
is possible in some cases to exploit conjugacy to marginalize out
parameters, which can lead to efficiency gains.</p>
<p>Neither the Hamiltonian Monte Carlo samplers or the optimizers make
use of conjugacy, working only on the log density and its derivatives.</p>

</div>
</div>
</div>
<h3><i style="font-size: 110%; color:#990017;">References</i></h3>
<div id="refs" class="references">
<div id="ref-Gelman:2006">
<p>Gelman, A. 2006. “Prior Distributions for Variance Parameters in Hierarchical Models.” <em>Bayesian Analysis</em> 1 (3): 515–34.</p>
</div>
<div id="ref-ChungEtAl:2013">
<p>Chung, Yeojin, Sophia Rabe-Hesketh, Vincent Dorie, Andrew Gelman, and Jingchen Liu. 2013. “A Nondegenerate Penalized Likelihood Estimator for Variance Parameters in Multilevel Models.” <em>Psychometrika</em> 78 (4): 685–709.</p>
</div>
<div id="ref-GelmanJakulinPittauEtAl:2008">
<p>Gelman, Andrew, Aleks Jakulin, Maria Grazia Pittau, and Yu-Sung Su. 2008. “A Weakly Informative Default Prior Distribution for Logistic and Other Regression Models.” <em>Annals of Applied Statistics</em> 2 (4): 1360–83.</p>
</div>
<div id="ref-LunnEtAl:2012">
<p>Lunn, David, Christopher Jackson, Nicky Best, Andrew Thomas, and David Spiegelhalter. 2012. <em>The BUGS Book: A Practical Introduction to Bayesian Analysis</em>. CRC Press/Chapman &amp; Hall.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>The practice was common in BUGS
and can be seen in most of their examples <span class="citation">Lunn et al. (<a href="#ref-LunnEtAl:2012">2012</a>)</span>.<a href="prior-distributions-and-models-for-data.html#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>This was also a popular strategy in the BUGS example models
<span class="citation">(Lunn et al. <a href="#ref-LunnEtAl:2012">2012</a>)</span>, which often went one step further and set the lower
bounds to a small number like 0.001 to discourage numerical underflow
to zero.<a href="prior-distributions-and-models-for-data.html#fnref2" class="footnote-back">↩</a></p></li>
<li id="fn3"><p>BUGS and JAGS both support
conjugate sampling through Gibbs sampling. JAGS extended the range of
conjugacy that could be exploited with its GLM module. Unlike Stan,
both BUGS and JAGS are restricted to conjugate priors for constrained
multivariate quantities such as covariance matrices or simplexes.<a href="prior-distributions-and-models-for-data.html#fnref3" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="simple-examples.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": null,
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"search": true,
"toolbar": {
"position": "static"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
