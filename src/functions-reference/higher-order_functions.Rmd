# Higher-Order Functions

Stan provides a few higher-order functions that act on other
functions.  In all cases, the function arguments to the higher-order
functions are defined as functions within the Stan language and passed
by name to the higher-order functions.

```{r results='asis', echo=FALSE}
if (knitr::is_html_output()) {
cat(' * <a href="functions-algebraic-solver.html">Algebraic Equation Solver</a>\n')
cat(' * <a href="functions-ode-solver.html">Ordinary Differential Equation (ODE) Solvers</a>\n')
cat(' * <a href="functions-1d-integrator.html">1D Integrator</a>\n')
cat(' * <a href="functions-reduce.html">Reduce-Sum</a>\n')
cat(' * <a href="functions-map.html">Map-Rect</a>\n')
}
```

## Algebraic Equation Solver {#functions-algebraic-solver}

Stan provides two built-in algebraic equation solvers,
respectively based on Powell's and Newton's methods.
The Newton method constitutes a more recent addition to Stan;
its use is recommended for most problems.
Although they look like other function applications, 
algebraic solvers are special in two ways.

First, an algebraic solver is a higher-order function, i.e. it takes
another function as one of its arguments. Other functions in
Stan which share this feature are the ordinary differential equation
solvers (see section [Ordinary Differential Equation (ODE) Solvers](#functions-ode-solver)).
Ordinary Stan functions do not allow functions as arguments.

Second, some of the arguments of the algebraic solvers are restricted
to data only expressions. These expressions must not contain variables
other than those declared in the data or transformed data blocks.
Ordinary Stan functions place no restriction on the origin of
variables in their argument expressions.

### Specifying an Algebraic Equation as a Function

An algebraic system is specified as an ordinary function in Stan
within the function block. The algebraic system function must have
this signature:

```
 vector algebra_system(vector y, vector theta,
                              real[] x_r, int[] x_i)
```

The algebraic system function should return the value of the algebraic
function which goes to 0, when we plug in the solution to the
algebraic system.

The argument of this function are:

*   *`y`*, the unknowns we wish to solve for

*   *`theta`*, parameter values used to evaluate the algebraic system

*   *`x_r`*, data values used to evaluate the algebraic system

*   *`x_i`*, integer data used to evaluate the algebraic system

The algebraic system function separates parameter values, *`theta`*,
from data values, *`x_r`*, for efficiency in propagating the derivatives
through the algebraic system.

### Call to the Algebraic Solver

<!-- vector; algebra_solver; (function algebra_system, vector y_guess, vector theta, real[] x_r, int[] x_i); -->
\index{{\tt \bfseries algebra\_solver }!{\tt (function algebra\_system, vector y\_guess, vector theta, real[] x\_r, int[] x\_i): vector}|hyperpage}

`vector` **`algebra_solver`**`(function algebra_system, vector y_guess, vector theta, real[] x_r, int[] x_i)`<br>\newline
Solves the algebraic system, given an initial guess, using the Powell
hybrid algorithm.

<!-- vector; algebra_solver; (function algebra_system, vector y_guess, vector theta, real[] x_r, int[] x_i, real rel_tol, real f_tol, int max_steps); -->
\index{{\tt \bfseries algebra\_solver }!{\tt (function algebra\_system, vector y\_guess, vector theta, real[] x\_r, int[] x\_i, real rel\_tol, real f\_tol, int max\_steps): vector}|hyperpage}

`vector` **`algebra_solver`**`(function algebra_system, vector y_guess, vector theta, real[] x_r, int[] x_i, real rel_tol, real f_tol, int max_steps)`<br>\newline
Solves the algebraic system, given an initial guess, using the Powell
hybrid algorithm with additional control parameters for the solver.

*Note:* In future releases, the function `algebra_solver` will be deprecated
and replaced with `algebra_solver_powell`.

\index{{\tt \bfseries algebra\_solver\_newton }!{\tt (function algebra\_system, vector y\_guess, vector theta, real[] x\_r, int[] x\_i): vector}|hyperpage}

`vector` **`algebra_solver_newton`**`(function algebra_system, vector y_guess, vector theta, real[] x_r, int[] x_i)`<br>\newline
Solves the algebraic system, given an initial guess, using Newton's method.

<!-- vector; algebra_solver; (function algebra_system, vector y_guess, vector theta, real[] x_r, int[] x_i, real rel_tol, real f_tol, int max_steps); -->
\index{{\tt \bfseries algebra\_solver\_newton }!{\tt (function algebra\_system, vector y\_guess, vector theta, real[] x\_r, int[] x\_i, real rel\_tol, real f\_tol, int max\_steps): vector}|hyperpage}

`vector` **`algebra_solver_newton`**`(function algebra_system, vector y_guess, vector theta, real[] x_r, int[] x_i, real rel_tol, real f_tol, int max_steps)`<br>\newline
Solves the algebraic system, given an initial guess, using Newton's method
with additional control parameters for the solver.

#### Arguments to the Algebraic Solver

The arguments to the algebraic solvers are as follows:

* *`algebra_system`*: function literal referring to a function
specifying the system of algebraic equations with signature
`(vector, vector, real[], int[]):vector`.   The arguments represent (1)
unknowns, (2) parameters, (3) real data, and   (4) integer data,
and the return value contains the value of the algebraic function,
which goes to 0 when we plug in the solution to the algebraic system,

*   *`y_guess`*: initial guess for the solution, type `vector`,

*   *`theta`*: parameters only, type `vector`,

*   *`x_r`*: real data only, type `real[]`, and

*   *`x_i`*: integer data only, type `int[]`.

For more fine-grained control of the algebraic solver, these
parameters can also be provided:

*   *`rel_tol`*: relative tolerance for the algebraic solver, type
`real`, data only,

*   *`function_tol`*: function tolerance for the algebraic solver,
type `real`, data only,

*   *`max_num_steps`*: maximum number of steps to take in the
algebraic solver, type `int`, data only.

#### Return value

The return value for the algebraic solver is an object of type
`vector`, with values which, when plugged in as `y` make the algebraic
function go to 0.

#### Sizes and parallel arrays

Certain sizes have to be consistent. The initial guess, return value
of the solver, and return value of the algebraic function must all be
the same size.

The parameters, real data, and integer data will be passed from the
solver directly to the system function.

#### Algorithmic details

Stan offers two algebraic solvers: `algebra_solver` and `algebra_solver_newton`.
`algebra_solver` is baed on the Powell hybrid method [@Powell:1970],
which in turn uses first-order derivatives. The Stan code builds on
the implementation of the hybrid solver in the unsupported module for
nonlinear optimization problems of the Eigen library [@Eigen:2013].
This solver is in turn based on the algorithm developed for the
package MINPACK-1 [@minpack:1980].

`algebra_solver_newton`, uses Newton's method,
also a first-order derivative based numerical solver.
The Stan code builds on the implementation in KINSOL
from the SUNDIALS suite [@Hindmarsh:2005].
For many problems, we find that `algebra_solver_newton` is faster 
than Powell's method.
If however Newton's method performs poorly, either failing to or requiring an excessively
long time to converge, the user should be prepared to switch
to `algebra_solver`.


For both solvers, the Jacobian of the solution
with respect to auxiliary parameters is
computed using the implicit function theorem. Intermediate Jacobians
(of the algebraic function's output with respect to the unknowns y
and with respect to the auxiliary parameters theta) are computed using
Stan's automatic differentiation.

## Ordinary Differential Equation (ODE) Solvers {#functions-ode-solver}

Stan provides several higher order functions for solving initial value
problems specified as Ordinary Differential Equations (ODEs).

Solving an initial value ODE means given a set of differential equations
$y'(t, \theta) = f(t, y, \theta)$ and initial conditions $y(t_0, \theta)$,
solving for $y$ at a sequence of times $t_0 < t_1 \leq t_2, \cdots \leq t_n$.
$f(t, y, \theta)$ is referred to here as the ODE system function.

$f(t, y, \theta)$ will be defined as a function with a certain signature
and provided along with the initial conditions and output times to one of the
ODE solver functions.

To make it easier to write ODEs, the solve functions take extra arguments
that are passed along unmodified to the user-supplied system function.
Because there can be any number of these arguments and they can be of different types,
they are denoted below as `...`. The types of the arguments represented by `...`
in the ODE solve function call must match the types of the arguments represented by
`...` in the user-supplied system function.

### Non-Stiff Solver

<!-- vector[]; ode_rk45; (function ode, vector initial_state, real initial_time, real[] times, ...); -->
\index{{\tt \bfseries ode\_rk45 }!{\tt (function ode, real[] initial\_state, real initial\_time, real[] times, ...): vector[]}|hyperpage}

`vector[]` **`ode_rk45`**`(function ode, vector initial_state, real initial_time, real[] times, ...)`<br>\newline
Solves the ODE system for the times provided using the Dormand-Prince
algorithm, a 4th/5th order Runge-Kutta method.

<!-- vector[]; ode_rk45_tol; (function ode, vector initial_state, real initial_time, real[] times, real rel_tol, real abs_tol, int max_num_steps, ...); -->
\index{{\tt \bfseries ode\_rk45\_tol }!{\tt (function ode, vector initial\_state, real initial\_time, real[] times, real rel\_tol, real abs\_tol, int max\_num\_steps, ...): vector[]}|hyperpage}

`vector[]` **`ode_rk45_tol`**`(function ode, vector initial_state, real initial_time, real[] times, real rel_tol, real abs_tol, int max_num_steps, ...)`<br>\newline
Solves the ODE system for the times provided using the Dormand-Prince
algorithm, a 4th/5th order Runge-Kutta method with additional control
parameters for the solver.

<!-- vector[]; ode_adams; (function ode, vector initial_state, real initial_time, real[] times, ...); -->
\index{{\tt \bfseries ode\_adams }!{\tt (function ode, vector initial\_state, real initial\_time, real[] times, ...): vector[]}|hyperpage}

`vector[]` **`ode_adams`**`(function ode, vector initial_state, real initial_time, real[] times, ...)`<br>\newline
Solves the ODE system for the times provided using the Adams-Moulton method.

<!-- vector[]; ode_adams_tol; (function ode, vector initial_state, real initial_time, real[] times, real rel_tol, real abs_tol, int max_num_steps, ...); -->
\index{{\tt \bfseries ode\_adams\_tol }!{\tt (function ode, vector initial\_state, real initial\_time, real[] times, data real rel\_tol, data real abs\_tol, data int max\_num\_steps, ...): vector[]}|hyperpage}

`vector[]` **`ode_adams_tol`**`(function ode, vector initial_state, real initial_time, real[] times, data real rel_tol, data real abs_tol, data int max_num_steps, ...)`<br>\newline
Solves the ODE system for the times provided using the Adams-Moulton
method with additional control parameters for the solver.

### Stiff Solver

<!-- vector[]; ode_bdf; (function ode, vector initial_state, real initial_time, real[] times, ...); -->
\index{{\tt \bfseries ode\_bdf }!{\tt (function ode, vector initial\_state, real initial\_time, real[] times, ...): vector[]}|hyperpage}

`vector[]` **`ode_bdf`**`(function ode, vector initial_state, real initial_time, real[] times, ...)`<br>\newline
Solves the ODE system for the times provided using the backward differentiation
formula (BDF) method.

<!-- vector[]; ode_bdf_tol; (function ode, vector initial_state, real initial_time, real[] times, real rel_tol, real abs_tol, int max_num_steps, ...); -->
\index{{\tt \bfseries ode\_bdf\_tol }!{\tt (function ode, vector initial\_state, real initial\_time, real[] times, data real rel\_tol, data real abs\_tol, data int max\_num\_steps, ...): vector[]}|hyperpage}

`vector[]` **`ode_bdf_tol`**`(function ode, vector initial_state, real initial_time, real[] times, data real rel_tol, data real abs_tol, data int max_num_steps, ...)`<br>\newline
Solves the ODE system for the times provided using the backward differentiation
formula (BDF) method with additional control parameters for the solver.

### ODE System Function

The first argument to one of the ODE solvers is always the ODE system
function. The ODE system function must have a `vector` return type, and the
first two arguments must be a `real` and `vector` in that order. These two
arguments are followed by the variadic arguments that are passed through from
the ODE solve function call:

```
 vector ode(real time, vector state, ...)
```

The ODE system function should return the derivative of the state with
respect to time at the time and state provided. The length of the returned
vector must match the length of the state input into the function.

The arguments to this function are:

*   *`time`*, the time to evaluate the ODE system

*   *`state`*, the state of the ODE system at the time specified

*   *`...`*, sequence of arguments passed unmodified from the ODE solve
function call. The types here must match the types in the `...` arguments of the
ODE solve function call.

### Arguments to the ODE solvers

The arguments to the ODE solvers in both the stiff and non-stiff solvers are the
same.

*   *`ode`*: ODE system function,

*   *`initial_state`*: initial state, type `vector`,

*   *`initial_time`*: initial time, type `int` or `real`,

*   *`times`*: solution times, type `real[]`,

*   *`...`*: sequence of arguments that will be passed through unmodified
to the ODE system function. The types here must match the types in the `...`
arguments of the ODE system function.

For the versions of the ode solver functions ending in `_tol`, these three
parameters must be provided after `times` and before the `...` arguments:

*   `data`   *`rel_tol`*: relative tolerance for the ODE  solver, type `real`,
data only,

*   `data`   *`abs_tol`*: absolute tolerance for the ODE  solver, type `real`,
data only, and

*   `data`   *`max_num_steps`*: maximum number of steps to take between output
times in the ODE solver, type `int`, data only.

Because these are all `data` arguments, they must be defined in either the data
or transformed data blocks. They cannot be parameters, transformed parameters
or functions of parameters or transformed parameters.

#### Return values

The return value for the ODE solvers is an array of vectors (type `vector[]`),
one vector representing the state of the system at every time in specified in
the `times` argument.

#### Array and vector sizes

The sizes must match, and in particular, the following groups are of
the same size:

*   state variables passed into the system function, derivatives
returned by the system function, initial state passed into the
solver, and length of each vector in the output,

*   number of solution times and number of vectors in the output,

## 1D Integrator {#functions-1d-integrator}

Stan provides a built-in mechanism to perform 1D integration of a function via quadrature methods.

It operates similarly to the [algebraic solver](#functions-algebraic-solver) and
the [ordinary differential equations solver](#functions-ode-solver) in that it allows as an argument a function.

Like both of those utilities, some of the arguments are limited
to data only expressions. These expressions must not contain variables
other than those declared in the data or transformed data blocks.

### Specifying an Integrand as a Function

Performing a 1D integration requires the integrand to be specified somehow.
This is done by defining a function in the Stan functions block with the special signature:

```
real integrand(real x, real xc, real[] theta,
                      real[] x_r, int[] x_i)
```

The function should return the value of the integrand evaluated at
the point x.

The argument of this function are:

* *`x`*, the independent variable being integrated over

* *`xc`*, a high precision version of the distance from x to the nearest endpoint in a definite integral (for more into see section [Precision Loss](#precision-loss)).

* *`theta`*, parameter values used to evaluate the integral

* *`x_r`*, data values used to evaluate the integral

* *`x_i`*, integer data used to evaluate the integral

Like algebraic solver and the differential equations solver, the 1D
integrator separates parameter values, `theta`, from data values, `x_r`.

### Call to the 1D Integrator

<!-- real; integrate_1d; (function integrand, real a, real b, real[] theta, real[] x_r, int[] x_i); -->
\index{{\tt \bfseries integrate\_1d }!{\tt (function integrand, real a, real b, real[] theta, real[] x\_r, int[] x\_i): real}|hyperpage}

`real` **`integrate_1d`** `(function integrand, real a, real b, real[] theta, real[] x_r, int[] x_i)`<br>\newline
Integrates the integrand from a to b.

<!-- real; integrate_1d; (function integrand, real a, real b, real[] theta, real[] x_r, int[] x_i), real relative_tolerance); -->
\index{{\tt \bfseries integrate\_1d }!{\tt (function integrand, real a, real b, real[] theta, real[] x\_r, int[] x\_i, real relative\_tolerance): real}|hyperpage}

`real` **`integrate_1d`** `(function integrand, real a, real b, real[] theta, real[] x_r, int[] x_i, real relative_tolerance)`<br>\newline
Integrates the integrand from a to b with the given relative tolerance.


#### Arguments to the 1D Integrator

The arguments to the 1D integrator are as follows:

* *`integrand`*: function literal referring to a function specifying the integrand with signature  `(real, real, real[], real[], int[]):real`
The arguments represent
    + (1) where integrand is evaluated,
    + (2) distance from evaluation point to integration limit for definite integrals,
    + (3) parameters,
    + (4) real data
    + (5) integer data, and the return value is the integrand evaluated at the given point,

* *`a`*: left limit of integration, may be negative infinity, type `real`,
* *`b`*: right limit of integration, may be positive infinity, type `real`,
* *`theta`*: parameters only, type `real[]`,
* *`x_r`*: real data only, type `real[]`,
* *`x_i`*: integer data only, type `int[]`.

A `relative_tolerance` argument can optionally be provided for more control over the algorithm:

* *`relative_tolerance`*: relative tolerance for the 1d integrator, type `real`, data only.

#### Return value

The return value for the 1D integrator is a `real`, the value of the integral.

#### Zero-crossing integrals {#zero-crossing}

For numeric stability, integrals on the (possibly infinite) interval $(a, b)$ that cross zero are split into two integrals, one from $(a, 0)$ and one from $(0, b)$. Each integral is separately integrated to the given `relative_tolerance`.

#### Precision loss near limits of integration in definite integrals {#precision-loss}

When integrating certain definite integrals, there can be significant precision loss in evaluating the integrand near the endpoints. This has to do with the breakdown in precision of double precision floating point values when adding or subtracting a small number from a number much larger than it in magnitude (for instance, `1.0 - x`). `xc` (as passed to the integrand) is a high-precision version of the distance between `x` and the definite integral endpoints and can be used to address this issue. More information (and an example where this is useful) is given in the User's Guide. For zero crossing integrals, `xc` will be a high precision version of the distance to the endpoints of the two smaller integrals. For any integral with an endpoint at negative infinity or positive infinity, `xc` is set to `NaN`.

#### Algorithmic details

Internally the 1D integrator uses the double-exponential methods in the Boost 1D quadrature library. Boost in turn makes use of quadrature methods developed in [@Takahasi:1974], [@Mori:1978], [@Bailey:2005], and [@Tanaka:2009].

The gradients of the integral are computed in accordance with the Leibniz integral rule. Gradients of the integrand are computed internally with Stan's automatic differentiation.

## Reduce-Sum Function {#functions-reduce}

Stan provides a higher-order reduce function for summation. A function
which returns a scalar `g: U -> real` is mapped to every element of a
list of type `U[]`, `{ x1, x2, ... }` and all the results are
accumulated,

`g(x1) + g(x2) + ...`

For efficiency reasons the reduce function doesn't work with the
element-wise evaluated function `g` itself, but instead works through
evaluating partial sums, `f: U[] -> real`, where:

```
f({ x1 }) = g(x1)
f({ x1, x2 }) = g(x1) + g(x2)
f({ x1, x2, ... }) = g(x1) + g(x2) + ...
```

Mathematically the summation reduction is associative and forming
arbitrary partial sums in an aribitrary order will not change the
result. However, floating point numerics on computers only have
a limited precision such that associativity does not hold
exactly. This implies that the order of summation determines the exact
numerical result. For this reason, the higher-order reduce function is
available in two variants:

* `reduce_sum`: Automatically choose partial sums partitioning based on a dynamic
 scheduling algorithm.
* `reduce_sum_static`: Compute the same sum as `reduce_sum`, but partition
 the input in the same way for given data set (in `reduce_sum` this partitioning
 might change depending on computer load). This should result in stable
 numerical evaluations.

### Specifying the Reduce-sum Function

The higher-order reduce function takes a partial sum function `f`, an array argument `x`
(with one array element for each term in the sum), a recommended
`grainsize`, and a set of shared arguments. This representation allows
parallelization of the resultant sum.

<!-- real; reduce_sum; (F f, T[] x, int grainsize, T1 s1, T2 s2, ...); -->
\index{{\tt \bfseries reduce\_sum }!{\tt (F f, T[] x, int grainsize, T1 s1, T2 s2, ...): real}|hyperpage}

`real` **`reduce_sum`**`(F f, T[] x, int grainsize, T1 s1, T2 s2, ...)`<br>\newline
`real` **`reduce_sum_static`**`(F f, T[] x, int grainsize, T1 s1, T2 s2, ...)`<br>\newline

Returns the equivalent of `f(x, 1, size(x), s1, s2, ...)`, but computes
the result in parallel by breaking the array `x` into independent
partial sums. `s1, s2, ...` are shared between all terms in the sum.

* *`f`*: function literal referring to a function specifying the
partial sum operation. Refer to the [partial sum function](#functions-partial-sum).
* *`x`*: array of `T`, one for each term of the reduction, `T` can be any type,
* *`grainsize`*: For `reduce_sum`, `grainsize` is the recommended size of the partial sum (`grainsize = 1` means pick totally automatically). For `reduce_sum_static`, `grainsize` determines the maximum size of the partial sums, type `int`,
* *`s1`*: first (optional) shared argument, type `T1`, where `T1` can be any type
* *`s2`*: second (optional) shared argument, type `T2`, where `T2` can be any type,
* *`...`*: remainder of shared arguments, each of which can be any type.

### The Partial sum Function {#functions-partial-sum}

The partial sum function must have the following signature where the type `T`, and the
types of all the shared arguments (`T1`, `T2`, ...) match those of the original
`reduce_sum` (`reduce_sum_static`) call.

```
(T[] x_subset, int start, int end, T1 s1, T2 s2, ...):real
```

The partial sum function returns the sum of the `start` to `end` terms (inclusive) of the overall
calculations. The arguments to the partial sum function are:

*   *`x_subset`*, the subset of `x` a given partial sum is responsible for computing, type `T[]`, where `T` matches the type of `x` in `reduce_sum` (`reduce_sum_static`)

*   *`start`*, the index of the first term of the partial sum, type `int`

*   *`end`*, the index of the last term of the partial sum (inclusive), type `int`

*   *`s1`*, first shared argument, type `T1`, matching type of `s1` in `reduce_sum` (`reduce_sum_static`)

*   *`s2`*, second shared argument, type `T2`, matching type of `s2` in `reduce_sum` (`reduce_sum_static`)

*   *`...`*, remainder of shared arguments, with types matching those in `reduce_sum` (`reduce_sum_static`)


## Map-Rect Function {#functions-map}

Stan provides a higher-order map function.  This allows map-reduce
functionality to be coded in Stan as described in the user's guide.

### Specifying the Mapped Function

The function being mapped must have a signature identical to that of
the function `f` in the following declaration.

```
 vector f(vector phi, vector theta,
          data real[] x_r, data int[] x_i);
```

The map function returns the sequence of results for the particular
shard being evaluated.  The arguments to the mapped function are:

*   *`phi`*, the sequence of parameters shared across shards

*   *`theta`*, the sequence of parameters specific to this shard

*   *`x_r`*, sequence of real-valued data

*   *`x_i`*, sequence of integer data

All input for the mapped function must be packed into these sequences
and all output from the mapped function must be packed into a single
vector.  The vector of output from each mapped function is
concatenated into the final result.

### Rectangular Map

The rectangular map function operates on rectangular (not ragged) data
structures, with parallel data structures for job-specific parameters,
job-specific real data, and job-specific integer data.

<!-- vector; map_rect; (F f, vector phi, vector[] theta, data real[,] x_r, data int[,] x_i); -->
\index{{\tt \bfseries map\_rect }!{\tt (F f, vector phi, vector[] theta, data real[,] x\_r, data int[,] x\_i): vector}|hyperpage}

`vector` **`map_rect`**`(F f, vector phi, vector[] theta, data real[,] x_r, data int[,] x_i)`<br>\newline
Return the concatenation of the results of applying the function f, of
type `(vector, vector, real[], int[]):vector` elementwise, i.e.,
`f(phi, theta[n], x_r[n], x_i[n])` for each `n` in `1:N`, where `N` is
the size of the parallel arrays of job-specific/local parameters
`theta`, real data `x_r`, and integer data `x_r`. The shared/global
parameters `phi` are passed to each invocation of `f`.

